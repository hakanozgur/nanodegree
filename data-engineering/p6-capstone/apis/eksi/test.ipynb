{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from src.crawler.api.api_helper import get_popular_topics, setup_session, get_todays_entries_from_topic\r\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "2"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "todays_topic_ids = []\r\n",
    "with open('./data/todays_topics.json', 'r', encoding='utf8') as write_file:\r\n",
    "    for item in write_file:\r\n",
    "        topic = json.loads(item)\r\n",
    "        todays_topic_ids.append(topic['TopicId'])\r\n",
    "len(todays_topic_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "658"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session = setup_session()\r\n",
    "todays_entries = []\r\n",
    "for topic_id in todays_topic_ids:\r\n",
    "    entries, topic = get_todays_entries_from_topic(session=session, topic_id=topic_id, page=1, entries=[])\r\n",
    "    todays_entries.extend(entries)\r\n",
    "len(todays_entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/todays_entries.json', 'w', encoding='utf8') as write_file:\r\n",
    "    for entry in todays_entries:\r\n",
    "        write_file.write(json.dumps(entry.dict(), ensure_ascii=False) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\r\n",
    "    todays_topic_ids = []\r\n",
    "    with open('./data/todays_topics.json', 'r', encoding='utf8') as write_file:\r\n",
    "        for item in write_file:\r\n",
    "            topic = json.loads(item)\r\n",
    "            todays_topic_ids.append(topic['TopicId'])\r\n",
    "    \r\n",
    "    session = setup_session()\r\n",
    "    with open('./data/todays_entries.json', 'a', encoding='utf8') as write_file:\r\n",
    "        for topic_id in todays_topic_ids:\r\n",
    "            entries, topic = get_todays_entries_from_topic(session=session, topic_id=topic_id, page=1, entries=[])\r\n",
    "            for entry in entries:\r\n",
    "                write_file.write(json.dumps(entry.dict(), ensure_ascii=False) + \"\\n\")\r\n",
    "except Exception as ex:\r\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/procesed_todays_topics.json', 'w', encoding='utf8') as write_file:\r\n",
    "    with open('../data/todays_topics.json', 'r', encoding='utf8') as topics_file:\r\n",
    "        for item in topics_file:\r\n",
    "            topic = json.loads(item)\r\n",
    "            new_json = {\r\n",
    "                'topic_id' : topic['TopicId'],\r\n",
    "                'topic_title' : topic['Title'],\r\n",
    "                'entry_count' : -1 if 'FullCount' not in topic else topic['FullCount'],\r\n",
    "                'created': '',\r\n",
    "                'slug': ''\r\n",
    "            }\r\n",
    "            write_file.write(json.dumps(new_json, ensure_ascii=False) + \"\\n\")\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "special_nl = 'Ç¶'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/procesed_todays_entries.json', 'w', encoding='utf8') as write_file:\r\n",
    "    with open('../data/todays_entries.json', 'r', encoding='utf8') as topics_file:\r\n",
    "        for item in topics_file:\r\n",
    "            entry = json.loads(item)\r\n",
    "\r\n",
    "            if entry['CommentSummary'] and 'Content' in entry['CommentSummary']:\r\n",
    "                entry['CommentSummary']['Content'] = entry['CommentSummary']['Content'].replace('\\r','').replace(\"\\n\",special_nl)\r\n",
    "\r\n",
    "            new_json = {\r\n",
    "                \"entry_id\" : entry['Id'],\r\n",
    "                \"author_nick\" : entry['Author']['Nick'],\r\n",
    "                \"author_id\" : entry['Author']['Id'],\r\n",
    "                \"created\" : entry['Created'],\r\n",
    "                \"last_updated\" : entry['LastUpdated'],\r\n",
    "                \"is_favorite\" : entry['IsFavorite'],\r\n",
    "                \"favorite_count\" : entry['FavoriteCount'],\r\n",
    "                \"hidden\" : entry['Hidden'],\r\n",
    "                \"active\" : entry['Active'],\r\n",
    "                \"comment_count\" : entry['CommentCount'],\r\n",
    "                \"comment_summary\" : entry['CommentSummary'],\r\n",
    "                \"avatar_url\" : entry['AvatarUrl'],\r\n",
    "                \"topic_id\" : entry['TopicId'],\r\n",
    "                \"topic_title\" : entry['TopicTitle'],\r\n",
    "                \"content\" : entry['Content'].replace('\\r','').replace(\"\\n\",special_nl),\r\n",
    "            }\r\n",
    "            write_file.write(json.dumps(new_json, ensure_ascii=False) + \"\\n\")\r\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('capstone': conda)",
   "name": "python3710jvsc74a57bd0407e9c27d0c9ec7efaa958bdf2ed052c986ab60a55ba4d9adbcf4b8da352d099"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}