{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://mmuratarat.github.io/2020-06-18/pyspark-postgresql-locally\r\n",
    "# https://www.youtube.com/watch?v=78FWrtEVYeA\r\n",
    "# https://opensource.com/article/18/11/pyspark-jupyter-notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configure local spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"PYSPARK_PYTHON\"]=\"jupyter\"\r\n",
    "os.environ[\"PYSPARK_DRIVER_PYTHON\"]=\"jupyter\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\r\n",
    "import sparknlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\r\n",
    "    .appName(\"capstone\")\\\r\n",
    "    .master(\"local[*]\")\\\r\n",
    "    .config(\"spark.driver.memory\",\"16G\")\\\r\n",
    "    .config(\"spark.driver.maxResultSize\", \"0\")\\\r\n",
    "    .config(\"spark.jars.packages\", \"com.johnsnowlabs.nlp:spark-nlp_2.12:3.0.1\")\\\r\n",
    "    .config(\"spark.kryoserializer.buffer.max\", \"2000m\")\\\r\n",
    "    .config(\"spark.jars\", \"postgresql-42.2.19.jar\")\\\r\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0.1\n",
      "3.1.1\n"
     ]
    }
   ],
   "source": [
    "print(sparknlp.version())\r\n",
    "print(spark.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_query = spark.read \\\r\n",
    "    .format(\"jdbc\") \\\r\n",
    "    .option(\"url\", \"jdbc:postgresql://localhost:6021/eksi\") \\\r\n",
    "    .option(\"user\", \"postgres\") \\\r\n",
    "    .option(\"password\", \"docker\") \\\r\n",
    "    .option(\"driver\", \"org.postgresql.Driver\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- entry_id: integer (nullable = true)\n",
      " |-- date_updated: timestamp (nullable = true)\n",
      " |-- date_created: timestamp (nullable = true)\n",
      " |-- author_id: integer (nullable = true)\n",
      " |-- topic_id: integer (nullable = true)\n",
      " |-- content: string (nullable = true)\n",
      " |-- favorite_count: integer (nullable = true)\n",
      " |-- comment_count: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_entries = base_query.option(\"dbtable\", \"entries\").load()\r\n",
    "df_entries.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- author_id: integer (nullable = true)\n",
      " |-- badges: string (nullable = true)\n",
      " |-- nick: string (nullable = true)\n",
      " |-- total_entry_count: integer (nullable = true)\n",
      " |-- last_entry_date: timestamp (nullable = true)\n",
      " |-- is_deactivated: boolean (nullable = true)\n",
      " |-- is_cursed: boolean (nullable = true)\n",
      " |-- follower_count: integer (nullable = true)\n",
      " |-- followings_count: integer (nullable = true)\n",
      " |-- picture_url: string (nullable = true)\n",
      " |-- favorite_entries: string (nullable = true)\n",
      " |-- favorited_entries: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_authors = base_query.option(\"dbtable\", \"authors\").load()\r\n",
    "df_authors.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- topic_id: integer (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- entry_count: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_topics = base_query.option(\"dbtable\", \"topics\").load()\r\n",
    "df_topics.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- date_created: timestamp (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- day: integer (nullable = true)\n",
      " |-- hour: integer (nullable = true)\n",
      " |-- week: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_entry_dates =  base_query.option(\"dbtable\", \"entry_dates\").load()\r\n",
    "df_entry_dates.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- date_updated: timestamp (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- day: integer (nullable = true)\n",
      " |-- hour: integer (nullable = true)\n",
      " |-- week: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_entry_update_dates = base_query.option(\"dbtable\", \"entry_update_dates\").load()\r\n",
    "df_entry_update_dates.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modify columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_entries = df_entries.drop(\"comment_count\").drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- entry_id: integer (nullable = true)\n",
      " |-- date_updated: timestamp (nullable = true)\n",
      " |-- date_created: timestamp (nullable = true)\n",
      " |-- author_id: integer (nullable = true)\n",
      " |-- topic_id: integer (nullable = true)\n",
      " |-- content: string (nullable = true)\n",
      " |-- favorite_count: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_entries.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_authors = df_authors.drop('is_deactivated', 'is_cursed','picture_url') .drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- author_id: integer (nullable = true)\n",
      " |-- badges: string (nullable = true)\n",
      " |-- nick: string (nullable = true)\n",
      " |-- total_entry_count: integer (nullable = true)\n",
      " |-- last_entry_date: timestamp (nullable = true)\n",
      " |-- follower_count: integer (nullable = true)\n",
      " |-- followings_count: integer (nullable = true)\n",
      " |-- favorite_entries: string (nullable = true)\n",
      " |-- favorited_entries: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_authors.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Badges explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_authors.createGlobalTempView(\"authors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "authors_with_badges = spark.sql(\"\"\"\r\n",
    "Select badges, author_id From global_temp.authors\r\n",
    "Where length(badges) > 1\r\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+---------+\n",
      "|         badges|author_id|\n",
      "+---------------+---------+\n",
      "|         azimli|    24956|\n",
      "|         azimli|    25113|\n",
      "|         azimli|    32345|\n",
      "|         azimli|    68363|\n",
      "|         azimli|   210965|\n",
      "|         merhum|   270348|\n",
      "|         azimli|   491243|\n",
      "|         azimli|   513363|\n",
      "|         azimli|   526608|\n",
      "|         azimli|   536725|\n",
      "|         azimli|   603986|\n",
      "|         azimli|   729738|\n",
      "|azimli,tasnif√ßi|   759951|\n",
      "|         azimli|   772773|\n",
      "|         azimli|   772789|\n",
      "|         azimli|   783288|\n",
      "|         azimli|   784487|\n",
      "|         azimli|   937849|\n",
      "|         azimli|  1000198|\n",
      "|         azimli|  1110869|\n",
      "+---------------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "authors_with_badges.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missing authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_authors.createGlobalTempView(\"authors\")\r\n",
    "df_entries.createGlobalTempView(\"entries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "authors_not_processed = spark.sql(\"\"\"\r\n",
    "Select distinct author_id From global_temp.entries Where author_id not in (\r\n",
    "\tSelect entries.author_id From global_temp.entries\r\n",
    "\tJoin global_temp.authors using(author_id)\r\n",
    ")\r\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|author_id|\n",
      "+---------+\n",
      "|   425654|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "authors_not_processed.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO add these authors to parse queue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\r\n",
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "\r\n",
    "from pyspark.ml import Pipeline\r\n",
    "from pyspark.sql import SparkSession\r\n",
    "import pyspark.sql.functions as F\r\n",
    "from sparknlp.annotator import *\r\n",
    "from sparknlp.base import *\r\n",
    "import sparknlp\r\n",
    "from sparknlp.pretrained import PretrainedPipeline\r\n",
    "\r\n",
    "spark = sparknlp.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"onto_100\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_list = [\r\n",
    "    \"\"\"William Henry Gates III (born October 28, 1955) is an American business magnate, software developer, investor, and philanthropist. He is best known as the co-founder of Microsoft Corporation. During his career at Microsoft, Gates held the positions of chairman, chief executive officer (CEO), president and chief software architect, while also being the largest individual shareholder until May 2014. He is one of the best-known entrepreneurs and pioneers of the microcomputer revolution of the 1970s and 1980s. Born and raised in Seattle, Washington, Gates co-founded Microsoft with childhood friend Paul Allen in 1975, in Albuquerque, New Mexico; it went on to become the world's largest personal computer software company. Gates led the company as chairman and CEO until stepping down as CEO in January 2000, but he remained chairman and became chief software architect. During the late 1990s, Gates had been criticized for his business tactics, which have been considered anti-competitive. This opinion has been upheld by numerous court rulings. In June 2006, Gates announced that he would be transitioning to a part-time role at Microsoft and full-time work at the Bill & Melinda Gates Foundation, the private charitable foundation that he and his wife, Melinda Gates, established in 2000.[9] He gradually transferred his duties to Ray Ozzie and Craig Mundie. He stepped down as chairman of Microsoft in February 2014 and assumed a new post as technology adviser to support the newly appointed CEO Satya Nadella.\"\"\",\r\n",
    "    \"\"\"The Mona Lisa is a 16th century oil painting created by Leonardo. It's held at the Louvre in Paris.\"\"\"\r\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glove_100d download started this may take some time.\n",
      "Approximate size to download 145.3 MB\n",
      "[OK!]\n",
      "onto_100 download started this may take some time.\n",
      "Approximate size to download 13.5 MB\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "documentAssembler = DocumentAssembler() \\\r\n",
    "    .setInputCol('text') \\\r\n",
    "    .setOutputCol('document')\r\n",
    "\r\n",
    "tokenizer = Tokenizer() \\\r\n",
    "    .setInputCols(['document']) \\\r\n",
    "    .setOutputCol('token')\r\n",
    "\r\n",
    "# ner_dl and onto_100 model are trained with glove_100d, so the embeddings in\r\n",
    "# the pipeline should match\r\n",
    "if (MODEL_NAME == \"ner_dl\") or (MODEL_NAME == \"onto_100\"):\r\n",
    "    embeddings = WordEmbeddingsModel.pretrained('glove_100d') \\\r\n",
    "        .setInputCols([\"document\", 'token']) \\\r\n",
    "        .setOutputCol(\"embeddings\")\r\n",
    "\r\n",
    "# Bert model uses Bert embeddings\r\n",
    "elif MODEL_NAME == \"ner_dl_bert\":\r\n",
    "    embeddings = BertEmbeddings.pretrained(name='bert_base_cased', lang='en') \\\r\n",
    "        .setInputCols(['document', 'token']) \\\r\n",
    "        .setOutputCol('embeddings')\r\n",
    "\r\n",
    "ner_model = NerDLModel.pretrained(MODEL_NAME, 'en') \\\r\n",
    "    .setInputCols(['document', 'token', 'embeddings']) \\\r\n",
    "    .setOutputCol('ner')\r\n",
    "\r\n",
    "ner_converter = NerConverter() \\\r\n",
    "    .setInputCols(['document', 'token', 'ner']) \\\r\n",
    "    .setOutputCol('ner_chunk')\r\n",
    "\r\n",
    "nlp_pipeline = Pipeline(stages=[\r\n",
    "    documentAssembler, \r\n",
    "    tokenizer,\r\n",
    "    embeddings,\r\n",
    "    ner_model,\r\n",
    "    ner_converter\r\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_df = spark.createDataFrame([['']]).toDF('text')\r\n",
    "pipeline_model = nlp_pipeline.fit(empty_df)\r\n",
    "df = spark.createDataFrame(pd.DataFrame({'text': text_list}))\r\n",
    "result = pipeline_model.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('capstone': conda)",
   "name": "python3710jvsc74a57bd0407e9c27d0c9ec7efaa958bdf2ed052c986ab60a55ba4d9adbcf4b8da352d099"
  },
  "language_info": {
   "name": "python",
   "version": ""
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}